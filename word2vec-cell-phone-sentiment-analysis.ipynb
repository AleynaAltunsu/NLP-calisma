{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9368706,"sourceType":"datasetVersion","datasetId":5681644}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gensim\nimport pandas as pd\n\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:21.755914Z","iopub.execute_input":"2024-09-30T09:33:21.756371Z","iopub.status.idle":"2024-09-30T09:33:41.161442Z","shell.execute_reply.started":"2024-09-30T09:33:21.756324Z","shell.execute_reply":"2024-09-30T09:33:41.159972Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"       reviewerID        asin      reviewerName helpful  \\\n0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n\n                                          reviewText  overall  \\\n0  They look good and stick good! I just don't li...        4   \n1  These stickers work like the review says they ...        5   \n2  These are awesome and make my phone look so st...        5   \n3  Item arrived in great time and was in perfect ...        4   \n4  awesome! stays on, and looks great. can be use...        5   \n\n                                     summary  unixReviewTime   reviewTime  \n0                                 Looks Good      1400630400  05 21, 2014  \n1                      Really great product.      1389657600  01 14, 2014  \n2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n3                                      Cute!      1382313600  10 21, 2013  \n4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A30TL5EWN6DFXT</td>\n      <td>120401325X</td>\n      <td>christina</td>\n      <td>[0, 0]</td>\n      <td>They look good and stick good! I just don't li...</td>\n      <td>4</td>\n      <td>Looks Good</td>\n      <td>1400630400</td>\n      <td>05 21, 2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASY55RVNIL0UD</td>\n      <td>120401325X</td>\n      <td>emily l.</td>\n      <td>[0, 0]</td>\n      <td>These stickers work like the review says they ...</td>\n      <td>5</td>\n      <td>Really great product.</td>\n      <td>1389657600</td>\n      <td>01 14, 2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2TMXE2AFO7ONB</td>\n      <td>120401325X</td>\n      <td>Erica</td>\n      <td>[0, 0]</td>\n      <td>These are awesome and make my phone look so st...</td>\n      <td>5</td>\n      <td>LOVE LOVE LOVE</td>\n      <td>1403740800</td>\n      <td>06 26, 2014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AWJ0WZQYMYFQ4</td>\n      <td>120401325X</td>\n      <td>JM</td>\n      <td>[4, 4]</td>\n      <td>Item arrived in great time and was in perfect ...</td>\n      <td>4</td>\n      <td>Cute!</td>\n      <td>1382313600</td>\n      <td>10 21, 2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATX7CZYFXI1KW</td>\n      <td>120401325X</td>\n      <td>patrice m rogoza</td>\n      <td>[2, 3]</td>\n      <td>awesome! stays on, and looks great. can be use...</td>\n      <td>5</td>\n      <td>leopard home button sticker for iphone 4s</td>\n      <td>1359849600</td>\n      <td>02 3, 2013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.164176Z","iopub.execute_input":"2024-09-30T09:33:41.164640Z","iopub.status.idle":"2024-09-30T09:33:41.173163Z","shell.execute_reply.started":"2024-09-30T09:33:41.164564Z","shell.execute_reply":"2024-09-30T09:33:41.171697Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(194439, 9)"},"metadata":{}}]},{"cell_type":"code","source":"df.reviewText[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.174954Z","iopub.execute_input":"2024-09-30T09:33:41.175407Z","iopub.status.idle":"2024-09-30T09:33:41.188074Z","shell.execute_reply.started":"2024-09-30T09:33:41.175360Z","shell.execute_reply":"2024-09-30T09:33:41.186875Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""},"metadata":{}}]},{"cell_type":"code","source":"review_text = df.reviewText.apply(gensim.utils.simple_preprocess)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.190194Z","iopub.execute_input":"2024-09-30T09:33:41.190759Z","iopub.status.idle":"2024-09-30T09:34:27.867380Z","shell.execute_reply.started":"2024-09-30T09:33:41.190690Z","shell.execute_reply":"2024-09-30T09:34:27.866260Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"review_text","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.871325Z","iopub.execute_input":"2024-09-30T09:34:27.871867Z","iopub.status.idle":"2024-09-30T09:34:27.886959Z","shell.execute_reply.started":"2024-09-30T09:34:27.871807Z","shell.execute_reply":"2024-09-30T09:34:27.885847Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0         [they, look, good, and, stick, good, just, don...\n1         [these, stickers, work, like, the, review, say...\n2         [these, are, awesome, and, make, my, phone, lo...\n3         [item, arrived, in, great, time, and, was, in,...\n4         [awesome, stays, on, and, looks, great, can, b...\n                                ...                        \n194434    [works, great, just, like, my, original, one, ...\n194435    [great, product, great, packaging, high, quali...\n194436    [this, is, great, cable, just, as, good, as, t...\n194437    [really, like, it, becasue, it, works, well, w...\n194438    [product, as, described, have, wasted, lot, of...\nName: reviewText, Length: 194439, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"review_text.loc[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.888322Z","iopub.execute_input":"2024-09-30T09:34:27.888813Z","iopub.status.idle":"2024-09-30T09:34:27.903858Z","shell.execute_reply.started":"2024-09-30T09:34:27.888770Z","shell.execute_reply":"2024-09-30T09:34:27.902292Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['they',\n 'look',\n 'good',\n 'and',\n 'stick',\n 'good',\n 'just',\n 'don',\n 'like',\n 'the',\n 'rounded',\n 'shape',\n 'because',\n 'was',\n 'always',\n 'bumping',\n 'it',\n 'and',\n 'siri',\n 'kept',\n 'popping',\n 'up',\n 'and',\n 'it',\n 'was',\n 'irritating',\n 'just',\n 'won',\n 'buy',\n 'product',\n 'like',\n 'this',\n 'again']"},"metadata":{}}]},{"cell_type":"code","source":"df.reviewText.loc[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.905359Z","iopub.execute_input":"2024-09-30T09:34:27.905811Z","iopub.status.idle":"2024-09-30T09:34:27.916330Z","shell.execute_reply.started":"2024-09-30T09:34:27.905762Z","shell.execute_reply":"2024-09-30T09:34:27.915172Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""},"metadata":{}}]},{"cell_type":"code","source":"model = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.918212Z","iopub.execute_input":"2024-09-30T09:34:27.918747Z","iopub.status.idle":"2024-09-30T09:34:27.929700Z","shell.execute_reply.started":"2024-09-30T09:34:27.918690Z","shell.execute_reply":"2024-09-30T09:34:27.928421Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.build_vocab(review_text, progress_per=1000)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.931339Z","iopub.execute_input":"2024-09-30T09:34:27.931972Z","iopub.status.idle":"2024-09-30T09:34:33.684071Z","shell.execute_reply.started":"2024-09-30T09:34:27.931914Z","shell.execute_reply":"2024-09-30T09:34:33.682827Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:33.685342Z","iopub.execute_input":"2024-09-30T09:34:33.685729Z","iopub.status.idle":"2024-09-30T09:35:52.511847Z","shell.execute_reply.started":"2024-09-30T09:34:33.685688Z","shell.execute_reply":"2024-09-30T09:35:52.510593Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(61508274, 83868975)"},"metadata":{}}]},{"cell_type":"code","source":"model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.513328Z","iopub.execute_input":"2024-09-30T09:35:52.513735Z","iopub.status.idle":"2024-09-30T09:35:52.602068Z","shell.execute_reply.started":"2024-09-30T09:35:52.513694Z","shell.execute_reply":"2024-09-30T09:35:52.600859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.wv.most_similar(\"bad\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.603454Z","iopub.execute_input":"2024-09-30T09:35:52.603858Z","iopub.status.idle":"2024-09-30T09:35:52.629405Z","shell.execute_reply.started":"2024-09-30T09:35:52.603816Z","shell.execute_reply":"2024-09-30T09:35:52.627480Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[('terrible', 0.6855090856552124),\n ('horrible', 0.6179935336112976),\n ('shabby', 0.6134233474731445),\n ('good', 0.596961259841919),\n ('disappointing', 0.5477627515792847),\n ('okay', 0.5419031977653503),\n ('poor', 0.5245140790939331),\n ('awful', 0.5205419659614563),\n ('funny', 0.5139976143836975),\n ('cheap', 0.5125272870063782)]"},"metadata":{}}]},{"cell_type":"code","source":"model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.631787Z","iopub.execute_input":"2024-09-30T09:35:52.632292Z","iopub.status.idle":"2024-09-30T09:35:52.642807Z","shell.execute_reply.started":"2024-09-30T09:35:52.632232Z","shell.execute_reply":"2024-09-30T09:35:52.641395Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.51016366"},"metadata":{}}]},{"cell_type":"code","source":"model.wv.similarity(w1=\"great\", w2=\"good\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.650470Z","iopub.execute_input":"2024-09-30T09:35:52.651618Z","iopub.status.idle":"2024-09-30T09:35:52.661844Z","shell.execute_reply.started":"2024-09-30T09:35:52.651517Z","shell.execute_reply":"2024-09-30T09:35:52.660251Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.7799677"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T09:35:52.664196Z","iopub.execute_input":"2024-09-30T09:35:52.665063Z","iopub.status.idle":"2024-09-30T09:35:52.679917Z","shell.execute_reply.started":"2024-09-30T09:35:52.664983Z","shell.execute_reply":"2024-09-30T09:35:52.678565Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****bundan sonrası nlp tutorial'ı\n","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize, word_tokenize\ntext= \"Hi John, How are you doing ? I will be travelling to your city. Lets catchup\"\nsent_tokenize(text)\nword_tokenize(text)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.681957Z","iopub.execute_input":"2024-09-30T09:35:52.682809Z","iopub.status.idle":"2024-09-30T09:35:53.608024Z","shell.execute_reply.started":"2024-09-30T09:35:52.682755Z","shell.execute_reply":"2024-09-30T09:35:53.606694Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['Hi',\n 'John',\n ',',\n 'How',\n 'are',\n 'you',\n 'doing',\n '?',\n 'I',\n 'will',\n 'be',\n 'travelling',\n 'to',\n 'your',\n 'city',\n '.',\n 'Lets',\n 'catchup']"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\nstemmer= PorterStemmer()\nprint ( stemmer.stem(\"playing\"))\nprint(stemmer.stem(\"plays\"))\nprint(stemmer.stem(\"played\"))\nprint(stemmer.stem(\"increases\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.609843Z","iopub.execute_input":"2024-09-30T09:35:53.610235Z","iopub.status.idle":"2024-09-30T09:35:53.617820Z","shell.execute_reply.started":"2024-09-30T09:35:53.610192Z","shell.execute_reply":"2024-09-30T09:35:53.616370Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"play\nplay\nplay\nincreas\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.619408Z","iopub.execute_input":"2024-09-30T09:35:53.619881Z","iopub.status.idle":"2024-09-30T09:35:53.805868Z","shell.execute_reply.started":"2024-09-30T09:35:53.619820Z","shell.execute_reply":"2024-09-30T09:35:53.804752Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\n\nnltk.data.path.append('/kaggle/input/cell-phones-andaccessories-5')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.807243Z","iopub.execute_input":"2024-09-30T09:35:53.807687Z","iopub.status.idle":"2024-09-30T09:35:53.816620Z","shell.execute_reply.started":"2024-09-30T09:35:53.807645Z","shell.execute_reply":"2024-09-30T09:35:53.815339Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\nword = \"koşmak\"\nlemma = lemmatizer.lemmatize(word)  # Çıktı: \"koş\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.818150Z","iopub.execute_input":"2024-09-30T09:35:53.818537Z","iopub.status.idle":"2024-09-30T09:35:54.527092Z","shell.execute_reply.started":"2024-09-30T09:35:53.818498Z","shell.execute_reply":"2024-09-30T09:35:54.525258Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet.zip/wordnet/.zip/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m      7\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkoşmak\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m lemma \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Çıktı: \"koş\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/stem/wordnet.py:40\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, pos\u001b[38;5;241m=\u001b[39mNOUN):\n\u001b[0;32m---> 40\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:116\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:78\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************","output_type":"error"}]},{"cell_type":"code","source":"import nltk\n\n# TRIED TO Download the necessary corpora\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\n\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemm = WordNetLemmatizer()\nprint(lemm.lemmatize(\"increases\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.528093Z","iopub.status.idle":"2024-09-30T09:35:54.528570Z","shell.execute_reply.started":"2024-09-30T09:35:54.528323Z","shell.execute_reply":"2024-09-30T09:35:54.528345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import pos_tag\ntext= \"Hi Johni How are you doing ? I will be travelling to your city. Lets Catchup\"\n\ntokens = word_tokenize(text)\npos_tag(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.530215Z","iopub.status.idle":"2024-09-30T09:35:54.530684Z","shell.execute_reply.started":"2024-09-30T09:35:54.530446Z","shell.execute_reply":"2024-09-30T09:35:54.530468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nwordnet.synsets('good')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.533026Z","iopub.status.idle":"2024-09-30T09:35:54.533542Z","shell.execute_reply.started":"2024-09-30T09:35:54.533270Z","shell.execute_reply":"2024-09-30T09:35:54.533293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nwordnet.synset('computer')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.534958Z","iopub.status.idle":"2024-09-30T09:35:54.535653Z","shell.execute_reply.started":"2024-09-30T09:35:54.535243Z","shell.execute_reply":"2024-09-30T09:35:54.535272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk  import ngrams\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\nsentence= \"I love to play football\"\n\nn=2\nfor gram in ngrams(word_tokenize(sentence), n):\n    print(gram)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.537570Z","iopub.status.idle":"2024-09-30T09:35:54.538206Z","shell.execute_reply.started":"2024-09-30T09:35:54.537897Z","shell.execute_reply":"2024-09-30T09:35:54.537930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****bundan sonrası contexto benzeri oyun denemesi****","metadata":{}},{"cell_type":"code","source":"import gensim\nimport pandas as pd\n\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\ndf.head()\n\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n\"\"\"# Kullanıcıdan ikinci kelimeyi al\nw2 = input(\"Lütfen bir kelime giriniz: \")\n\n# Benzerlik skorunu hesapla ve yazdır\nsimilarity_score = model.wv.similarity(w1=\"cheap\", w2=w2)\n\nprint(f\"gizli kelime ile kelimen arasındaki benzerlik skoru: {similarity_score}\")\"\"\"\nimport random\n\n# Modeldeki kelimelerden rastgele birini seç\nw1 = random.choice(model.wv.index_to_key)\n#print(f\"Seçilen kelime: {w1}\")\n\n\nwhile True:\n    w3 = input(\"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz): \")\n\n    if w3.lower() == \"çıkış\":\n        print(\"Oyunu bıraktınız.\")\n        print(f\"Seçilen kelime: {w1}\")\n        break\n    w2 = input(\"Lütfen bir kelime giriniz: \")\n        \n    similarity_score = model.wv.similarity(w1=w1, w2=w2)\n    print(f\"gizli kelime ile kelimen arasındaki benzerlik skoru: {similarity_score}\")    \n\n\n    if similarity_score >= 0.8:  # Örneğin, 0.8 ve üzeri bir skor doğru kabul edilebilir\n        if similarity_score == 1:  # Örneğin, 0.8 ve üzeri bir skor doğru kabul edilebilir\n            print(\"Tebrikler! Doğru tahmin!\")\n            break\n        print(\"Tebrikler! Doğru tahmin sayılır!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.540510Z","iopub.status.idle":"2024-09-30T09:35:54.541159Z","shell.execute_reply.started":"2024-09-30T09:35:54.540850Z","shell.execute_reply":"2024-09-30T09:35:54.540881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vektörel hesaplama","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.543676Z","iopub.status.idle":"2024-09-30T09:35:54.544111Z","shell.execute_reply.started":"2024-09-30T09:35:54.543899Z","shell.execute_reply":"2024-09-30T09:35:54.543920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yükle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n# Metin verilerini kelime listelerine dönüştür\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluştur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seç\nw1 = random.choice(model.wv.index_to_key)\n#w1=\"queen\"\nprint(w1)\ndef cosine_similarity(vec1, vec2):\n    dot_product = np.dot(vec1, vec2)\n    norm_vec1 = np.linalg.norm(vec1)\n    norm_vec2 = np.linalg.norm(vec2)\n    return dot_product / (norm_vec1 * norm_vec2)\n\nwhile True:\n    w3 = input(\"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz): \")\n\n    if w3.lower() == \"çıkış\":\n        print(\"Oyunu bıraktınız.\")\n        print(f\"Seçilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"Lütfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"Girdiğiniz kelime modelde bulunamadı.\")\n        continue\n    \n    # w1 ve w2 için vektörleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # Kosinüs benzerliğini hesapla\n    similarity_score = cosine_similarity(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasındaki benzerlik skoru: {similarity_score}\")    \n\n    if similarity_score >= 0.8:\n        if similarity_score == 1:\n            print(\"Tebrikler! Doğru tahmin!\")\n            break\n        print(\"Tebrikler! Doğru tahmin sayılır!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:36:20.261058Z","iopub.execute_input":"2024-09-30T09:36:20.261514Z","iopub.status.idle":"2024-09-30T09:39:54.377529Z","shell.execute_reply.started":"2024-09-30T09:36:20.261467Z","shell.execute_reply":"2024-09-30T09:39:54.376266Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"monoprice.com\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz):  kral\nLütfen bir kelime giriniz:  kral\n"},{"name":"stdout","text":"Girdiğiniz kelime modelde bulunamadı.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz):  king\nLütfen bir kelime giriniz:  king\n"},{"name":"stdout","text":"gizli kelime ile kelimen arasındaki benzerlik skoru: 0.5102458000183105\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz):  mkj\nLütfen bir kelime giriniz:  monoprice.com\n"},{"name":"stdout","text":"gizli kelime ile kelimen arasındaki benzerlik skoru: 1.0\nTebrikler! Doğru tahmin!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"bundan sonraki cell mesafeyi öklidiyen hesaplıyor. Öklidyen Mesafe ile Vektörel Yakınlık Hesaplama\nÖklidyen mesafe, iki vektör arasındaki düz çizgi mesafesini ölçer. Matematiksel olarak, iki vektör \n𝑣\n1\nv \n1\n​\n  ve \n𝑣\n2\nv \n2\n​\n  arasındaki Öklidyen mesafe şu şekilde hesaplanır:\n\nEuclidean Distance\n=\n∑\n𝑖\n=\n1\n𝑛\n(\n𝑣\n1\n,\n𝑖\n−\n𝑣\n2\n,\n𝑖\n)\n2\nEuclidean Distance= \ni=1\n∑\nn\n​\n (v \n1,i\n​\n −v \n2,i\n​\n ) \n2\n \n\n\nimport gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yükle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n\n# Metin verilerini kelime listelerine dönüştür\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluştur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seç\n#w1 = random.choice(model.wv.index_to_key)\nW1= \"queen\"\n\ndef euclidean_distance(vec1, vec2):\n    return np.linalg.norm(vec1 - vec2)\n\nwhile True:\n    w3 = input(\"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz): \")\n\n    if w3.lower() == \"çıkış\":\n        print(\"Oyunu bıraktınız.\")\n        print(f\"Seçilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"Lütfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"Girdiğiniz kelime modelde bulunamadı.\")\n        continue\n    \n    # w1 ve w2 için vektörleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # Öklidyen mesafeyi hesapla\n    distance = euclidean_distance(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasındaki vektörel uzaklık: {distance}\")    \n\n    # Mesafeye dayalı bir eşik değeri belirleyebiliriz\n    if distance <= 0.5:  # Örneğin, 0.5 veya daha küçük bir mesafe yakın kabul edilebilir\n        print(\"Tebrikler! Doğru tahmin sayılır!\")\n        break\n","metadata":{}},{"cell_type":"markdown","source":"vektörel mesafeyi pisagor teoremi ile hesaplıyor sonraki cell.\n","metadata":{}},{"cell_type":"code","source":"import gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yükle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n# Metin verilerini kelime listelerine dönüştür\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluştur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seç\nw1 = random.choice(model.wv.index_to_key)\n#w1=\"queen\"\n\ndef pythagorean_distance(vec1, vec2):\n    # Bileşen farklarının karelerini topla ve karekökünü al\n    return np.sqrt(np.sum((vec1 - vec2) ** 2))\n\nwhile True:\n    w3 = input(\"rastgele bir şeyler yaz devam etmek için (çıkmak için 'çıkış' yaz): \")\n\n    if w3.lower() == \"çıkış\":\n        print(\"Oyunu bıraktınız.\")\n        print(f\"Seçilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"Lütfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"Girdiğiniz kelime modelde bulunamadı.\")\n        continue\n    \n    # w1 ve w2 için vektörleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # Pisagor Teoremi ile mesafeyi hesapla\n    distance = pythagorean_distance(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasındaki vektörel uzaklık: {distance}\")    \n\n    # Mesafeye dayalı bir eşik değeri belirleyebiliriz\n    if distance <= 0.5:  # Örneğin, 0.5 veya daha küçük bir mesafe yakın kabul edilebilir\n        print(\"Tebrikler! Doğru tahmin sayılır!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:43:16.114887Z","iopub.execute_input":"2024-09-30T09:43:16.115400Z"},"trusted":true},"execution_count":null,"outputs":[]}]}