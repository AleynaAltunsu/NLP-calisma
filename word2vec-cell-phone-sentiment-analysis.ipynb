{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9368706,"sourceType":"datasetVersion","datasetId":5681644}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gensim\nimport pandas as pd\n\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:21.755914Z","iopub.execute_input":"2024-09-30T09:33:21.756371Z","iopub.status.idle":"2024-09-30T09:33:41.161442Z","shell.execute_reply.started":"2024-09-30T09:33:21.756324Z","shell.execute_reply":"2024-09-30T09:33:41.159972Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"       reviewerID        asin      reviewerName helpful  \\\n0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n\n                                          reviewText  overall  \\\n0  They look good and stick good! I just don't li...        4   \n1  These stickers work like the review says they ...        5   \n2  These are awesome and make my phone look so st...        5   \n3  Item arrived in great time and was in perfect ...        4   \n4  awesome! stays on, and looks great. can be use...        5   \n\n                                     summary  unixReviewTime   reviewTime  \n0                                 Looks Good      1400630400  05 21, 2014  \n1                      Really great product.      1389657600  01 14, 2014  \n2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n3                                      Cute!      1382313600  10 21, 2013  \n4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A30TL5EWN6DFXT</td>\n      <td>120401325X</td>\n      <td>christina</td>\n      <td>[0, 0]</td>\n      <td>They look good and stick good! I just don't li...</td>\n      <td>4</td>\n      <td>Looks Good</td>\n      <td>1400630400</td>\n      <td>05 21, 2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ASY55RVNIL0UD</td>\n      <td>120401325X</td>\n      <td>emily l.</td>\n      <td>[0, 0]</td>\n      <td>These stickers work like the review says they ...</td>\n      <td>5</td>\n      <td>Really great product.</td>\n      <td>1389657600</td>\n      <td>01 14, 2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2TMXE2AFO7ONB</td>\n      <td>120401325X</td>\n      <td>Erica</td>\n      <td>[0, 0]</td>\n      <td>These are awesome and make my phone look so st...</td>\n      <td>5</td>\n      <td>LOVE LOVE LOVE</td>\n      <td>1403740800</td>\n      <td>06 26, 2014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AWJ0WZQYMYFQ4</td>\n      <td>120401325X</td>\n      <td>JM</td>\n      <td>[4, 4]</td>\n      <td>Item arrived in great time and was in perfect ...</td>\n      <td>4</td>\n      <td>Cute!</td>\n      <td>1382313600</td>\n      <td>10 21, 2013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATX7CZYFXI1KW</td>\n      <td>120401325X</td>\n      <td>patrice m rogoza</td>\n      <td>[2, 3]</td>\n      <td>awesome! stays on, and looks great. can be use...</td>\n      <td>5</td>\n      <td>leopard home button sticker for iphone 4s</td>\n      <td>1359849600</td>\n      <td>02 3, 2013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.164176Z","iopub.execute_input":"2024-09-30T09:33:41.164640Z","iopub.status.idle":"2024-09-30T09:33:41.173163Z","shell.execute_reply.started":"2024-09-30T09:33:41.164564Z","shell.execute_reply":"2024-09-30T09:33:41.171697Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(194439, 9)"},"metadata":{}}]},{"cell_type":"code","source":"df.reviewText[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.174954Z","iopub.execute_input":"2024-09-30T09:33:41.175407Z","iopub.status.idle":"2024-09-30T09:33:41.188074Z","shell.execute_reply.started":"2024-09-30T09:33:41.175360Z","shell.execute_reply":"2024-09-30T09:33:41.186875Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""},"metadata":{}}]},{"cell_type":"code","source":"review_text = df.reviewText.apply(gensim.utils.simple_preprocess)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:33:41.190194Z","iopub.execute_input":"2024-09-30T09:33:41.190759Z","iopub.status.idle":"2024-09-30T09:34:27.867380Z","shell.execute_reply.started":"2024-09-30T09:33:41.190690Z","shell.execute_reply":"2024-09-30T09:34:27.866260Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"review_text","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.871325Z","iopub.execute_input":"2024-09-30T09:34:27.871867Z","iopub.status.idle":"2024-09-30T09:34:27.886959Z","shell.execute_reply.started":"2024-09-30T09:34:27.871807Z","shell.execute_reply":"2024-09-30T09:34:27.885847Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0         [they, look, good, and, stick, good, just, don...\n1         [these, stickers, work, like, the, review, say...\n2         [these, are, awesome, and, make, my, phone, lo...\n3         [item, arrived, in, great, time, and, was, in,...\n4         [awesome, stays, on, and, looks, great, can, b...\n                                ...                        \n194434    [works, great, just, like, my, original, one, ...\n194435    [great, product, great, packaging, high, quali...\n194436    [this, is, great, cable, just, as, good, as, t...\n194437    [really, like, it, becasue, it, works, well, w...\n194438    [product, as, described, have, wasted, lot, of...\nName: reviewText, Length: 194439, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"review_text.loc[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.888322Z","iopub.execute_input":"2024-09-30T09:34:27.888813Z","iopub.status.idle":"2024-09-30T09:34:27.903858Z","shell.execute_reply.started":"2024-09-30T09:34:27.888770Z","shell.execute_reply":"2024-09-30T09:34:27.902292Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['they',\n 'look',\n 'good',\n 'and',\n 'stick',\n 'good',\n 'just',\n 'don',\n 'like',\n 'the',\n 'rounded',\n 'shape',\n 'because',\n 'was',\n 'always',\n 'bumping',\n 'it',\n 'and',\n 'siri',\n 'kept',\n 'popping',\n 'up',\n 'and',\n 'it',\n 'was',\n 'irritating',\n 'just',\n 'won',\n 'buy',\n 'product',\n 'like',\n 'this',\n 'again']"},"metadata":{}}]},{"cell_type":"code","source":"df.reviewText.loc[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.905359Z","iopub.execute_input":"2024-09-30T09:34:27.905811Z","iopub.status.idle":"2024-09-30T09:34:27.916330Z","shell.execute_reply.started":"2024-09-30T09:34:27.905762Z","shell.execute_reply":"2024-09-30T09:34:27.915172Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""},"metadata":{}}]},{"cell_type":"code","source":"model = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.918212Z","iopub.execute_input":"2024-09-30T09:34:27.918747Z","iopub.status.idle":"2024-09-30T09:34:27.929700Z","shell.execute_reply.started":"2024-09-30T09:34:27.918690Z","shell.execute_reply":"2024-09-30T09:34:27.928421Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.build_vocab(review_text, progress_per=1000)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:27.931339Z","iopub.execute_input":"2024-09-30T09:34:27.931972Z","iopub.status.idle":"2024-09-30T09:34:33.684071Z","shell.execute_reply.started":"2024-09-30T09:34:27.931914Z","shell.execute_reply":"2024-09-30T09:34:33.682827Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:34:33.685342Z","iopub.execute_input":"2024-09-30T09:34:33.685729Z","iopub.status.idle":"2024-09-30T09:35:52.511847Z","shell.execute_reply.started":"2024-09-30T09:34:33.685688Z","shell.execute_reply":"2024-09-30T09:35:52.510593Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(61508274, 83868975)"},"metadata":{}}]},{"cell_type":"code","source":"model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.513328Z","iopub.execute_input":"2024-09-30T09:35:52.513735Z","iopub.status.idle":"2024-09-30T09:35:52.602068Z","shell.execute_reply.started":"2024-09-30T09:35:52.513694Z","shell.execute_reply":"2024-09-30T09:35:52.600859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.wv.most_similar(\"bad\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.603454Z","iopub.execute_input":"2024-09-30T09:35:52.603858Z","iopub.status.idle":"2024-09-30T09:35:52.629405Z","shell.execute_reply.started":"2024-09-30T09:35:52.603816Z","shell.execute_reply":"2024-09-30T09:35:52.627480Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[('terrible', 0.6855090856552124),\n ('horrible', 0.6179935336112976),\n ('shabby', 0.6134233474731445),\n ('good', 0.596961259841919),\n ('disappointing', 0.5477627515792847),\n ('okay', 0.5419031977653503),\n ('poor', 0.5245140790939331),\n ('awful', 0.5205419659614563),\n ('funny', 0.5139976143836975),\n ('cheap', 0.5125272870063782)]"},"metadata":{}}]},{"cell_type":"code","source":"model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.631787Z","iopub.execute_input":"2024-09-30T09:35:52.632292Z","iopub.status.idle":"2024-09-30T09:35:52.642807Z","shell.execute_reply.started":"2024-09-30T09:35:52.632232Z","shell.execute_reply":"2024-09-30T09:35:52.641395Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.51016366"},"metadata":{}}]},{"cell_type":"code","source":"model.wv.similarity(w1=\"great\", w2=\"good\")","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.650470Z","iopub.execute_input":"2024-09-30T09:35:52.651618Z","iopub.status.idle":"2024-09-30T09:35:52.661844Z","shell.execute_reply.started":"2024-09-30T09:35:52.651517Z","shell.execute_reply":"2024-09-30T09:35:52.660251Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.7799677"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T09:35:52.664196Z","iopub.execute_input":"2024-09-30T09:35:52.665063Z","iopub.status.idle":"2024-09-30T09:35:52.679917Z","shell.execute_reply.started":"2024-09-30T09:35:52.664983Z","shell.execute_reply":"2024-09-30T09:35:52.678565Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****bundan sonrasÄ± nlp tutorial'Ä±\n","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize, word_tokenize\ntext= \"Hi John, How are you doing ? I will be travelling to your city. Lets catchup\"\nsent_tokenize(text)\nword_tokenize(text)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:52.681957Z","iopub.execute_input":"2024-09-30T09:35:52.682809Z","iopub.status.idle":"2024-09-30T09:35:53.608024Z","shell.execute_reply.started":"2024-09-30T09:35:52.682755Z","shell.execute_reply":"2024-09-30T09:35:53.606694Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['Hi',\n 'John',\n ',',\n 'How',\n 'are',\n 'you',\n 'doing',\n '?',\n 'I',\n 'will',\n 'be',\n 'travelling',\n 'to',\n 'your',\n 'city',\n '.',\n 'Lets',\n 'catchup']"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\nstemmer= PorterStemmer()\nprint ( stemmer.stem(\"playing\"))\nprint(stemmer.stem(\"plays\"))\nprint(stemmer.stem(\"played\"))\nprint(stemmer.stem(\"increases\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.609843Z","iopub.execute_input":"2024-09-30T09:35:53.610235Z","iopub.status.idle":"2024-09-30T09:35:53.617820Z","shell.execute_reply.started":"2024-09-30T09:35:53.610192Z","shell.execute_reply":"2024-09-30T09:35:53.616370Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"play\nplay\nplay\nincreas\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\n\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.619408Z","iopub.execute_input":"2024-09-30T09:35:53.619881Z","iopub.status.idle":"2024-09-30T09:35:53.805868Z","shell.execute_reply.started":"2024-09-30T09:35:53.619820Z","shell.execute_reply":"2024-09-30T09:35:53.804752Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\n\nnltk.data.path.append('/kaggle/input/cell-phones-andaccessories-5')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.807243Z","iopub.execute_input":"2024-09-30T09:35:53.807687Z","iopub.status.idle":"2024-09-30T09:35:53.816620Z","shell.execute_reply.started":"2024-09-30T09:35:53.807645Z","shell.execute_reply":"2024-09-30T09:35:53.815339Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\nword = \"koÅŸmak\"\nlemma = lemmatizer.lemmatize(word)  # Ã‡Ä±ktÄ±: \"koÅŸ\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:53.818150Z","iopub.execute_input":"2024-09-30T09:35:53.818537Z","iopub.status.idle":"2024-09-30T09:35:54.527092Z","shell.execute_reply.started":"2024-09-30T09:35:53.818498Z","shell.execute_reply":"2024-09-30T09:35:54.525258Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet.zip/wordnet/.zip/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[1;32m      7\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkoÅŸmak\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m lemma \u001b[38;5;241m=\u001b[39m \u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ã‡Ä±ktÄ±: \"koÅŸ\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/stem/wordnet.py:40\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, pos\u001b[38;5;241m=\u001b[39mNOUN):\n\u001b[0;32m---> 40\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m(word, pos)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:116\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/corpus/util.py:78\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m: root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:653\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    651\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    652\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource 'corpora/wordnet' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/kaggle/input/cell-phones-andaccessories-5'\n**********************************************************************","output_type":"error"}]},{"cell_type":"code","source":"import nltk\n\n# TRIED TO Download the necessary corpora\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\n\n\nfrom nltk.stem import WordNetLemmatizer\n\nlemm = WordNetLemmatizer()\nprint(lemm.lemmatize(\"increases\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.528093Z","iopub.status.idle":"2024-09-30T09:35:54.528570Z","shell.execute_reply.started":"2024-09-30T09:35:54.528323Z","shell.execute_reply":"2024-09-30T09:35:54.528345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk import pos_tag\ntext= \"Hi Johni How are you doing ? I will be travelling to your city. Lets Catchup\"\n\ntokens = word_tokenize(text)\npos_tag(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.530215Z","iopub.status.idle":"2024-09-30T09:35:54.530684Z","shell.execute_reply.started":"2024-09-30T09:35:54.530446Z","shell.execute_reply":"2024-09-30T09:35:54.530468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nwordnet.synsets('good')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.533026Z","iopub.status.idle":"2024-09-30T09:35:54.533542Z","shell.execute_reply.started":"2024-09-30T09:35:54.533270Z","shell.execute_reply":"2024-09-30T09:35:54.533293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet\nwordnet.synset('computer')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.534958Z","iopub.status.idle":"2024-09-30T09:35:54.535653Z","shell.execute_reply.started":"2024-09-30T09:35:54.535243Z","shell.execute_reply":"2024-09-30T09:35:54.535272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk  import ngrams\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\nsentence= \"I love to play football\"\n\nn=2\nfor gram in ngrams(word_tokenize(sentence), n):\n    print(gram)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.537570Z","iopub.status.idle":"2024-09-30T09:35:54.538206Z","shell.execute_reply.started":"2024-09-30T09:35:54.537897Z","shell.execute_reply":"2024-09-30T09:35:54.537930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****bundan sonrasÄ± contexto benzeri oyun denemesi****","metadata":{}},{"cell_type":"code","source":"import gensim\nimport pandas as pd\n\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\ndf.head()\n\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n\"\"\"# KullanÄ±cÄ±dan ikinci kelimeyi al\nw2 = input(\"LÃ¼tfen bir kelime giriniz: \")\n\n# Benzerlik skorunu hesapla ve yazdÄ±r\nsimilarity_score = model.wv.similarity(w1=\"cheap\", w2=w2)\n\nprint(f\"gizli kelime ile kelimen arasÄ±ndaki benzerlik skoru: {similarity_score}\")\"\"\"\nimport random\n\n# Modeldeki kelimelerden rastgele birini seÃ§\nw1 = random.choice(model.wv.index_to_key)\n#print(f\"SeÃ§ilen kelime: {w1}\")\n\n\nwhile True:\n    w3 = input(\"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz): \")\n\n    if w3.lower() == \"Ã§Ä±kÄ±ÅŸ\":\n        print(\"Oyunu bÄ±raktÄ±nÄ±z.\")\n        print(f\"SeÃ§ilen kelime: {w1}\")\n        break\n    w2 = input(\"LÃ¼tfen bir kelime giriniz: \")\n        \n    similarity_score = model.wv.similarity(w1=w1, w2=w2)\n    print(f\"gizli kelime ile kelimen arasÄ±ndaki benzerlik skoru: {similarity_score}\")    \n\n\n    if similarity_score >= 0.8:  # Ã–rneÄŸin, 0.8 ve Ã¼zeri bir skor doÄŸru kabul edilebilir\n        if similarity_score == 1:  # Ã–rneÄŸin, 0.8 ve Ã¼zeri bir skor doÄŸru kabul edilebilir\n            print(\"Tebrikler! DoÄŸru tahmin!\")\n            break\n        print(\"Tebrikler! DoÄŸru tahmin sayÄ±lÄ±r!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.540510Z","iopub.status.idle":"2024-09-30T09:35:54.541159Z","shell.execute_reply.started":"2024-09-30T09:35:54.540850Z","shell.execute_reply":"2024-09-30T09:35:54.540881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vektÃ¶rel hesaplama","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:35:54.543676Z","iopub.status.idle":"2024-09-30T09:35:54.544111Z","shell.execute_reply.started":"2024-09-30T09:35:54.543899Z","shell.execute_reply":"2024-09-30T09:35:54.543920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yÃ¼kle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n# Metin verilerini kelime listelerine dÃ¶nÃ¼ÅŸtÃ¼r\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluÅŸtur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seÃ§\nw1 = random.choice(model.wv.index_to_key)\n#w1=\"queen\"\nprint(w1)\ndef cosine_similarity(vec1, vec2):\n    dot_product = np.dot(vec1, vec2)\n    norm_vec1 = np.linalg.norm(vec1)\n    norm_vec2 = np.linalg.norm(vec2)\n    return dot_product / (norm_vec1 * norm_vec2)\n\nwhile True:\n    w3 = input(\"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz): \")\n\n    if w3.lower() == \"Ã§Ä±kÄ±ÅŸ\":\n        print(\"Oyunu bÄ±raktÄ±nÄ±z.\")\n        print(f\"SeÃ§ilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"LÃ¼tfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"GirdiÄŸiniz kelime modelde bulunamadÄ±.\")\n        continue\n    \n    # w1 ve w2 iÃ§in vektÃ¶rleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # KosinÃ¼s benzerliÄŸini hesapla\n    similarity_score = cosine_similarity(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasÄ±ndaki benzerlik skoru: {similarity_score}\")    \n\n    if similarity_score >= 0.8:\n        if similarity_score == 1:\n            print(\"Tebrikler! DoÄŸru tahmin!\")\n            break\n        print(\"Tebrikler! DoÄŸru tahmin sayÄ±lÄ±r!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:36:20.261058Z","iopub.execute_input":"2024-09-30T09:36:20.261514Z","iopub.status.idle":"2024-09-30T09:39:54.377529Z","shell.execute_reply.started":"2024-09-30T09:36:20.261467Z","shell.execute_reply":"2024-09-30T09:39:54.376266Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"monoprice.com\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz):  kral\nLÃ¼tfen bir kelime giriniz:  kral\n"},{"name":"stdout","text":"GirdiÄŸiniz kelime modelde bulunamadÄ±.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz):  king\nLÃ¼tfen bir kelime giriniz:  king\n"},{"name":"stdout","text":"gizli kelime ile kelimen arasÄ±ndaki benzerlik skoru: 0.5102458000183105\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz):  mkj\nLÃ¼tfen bir kelime giriniz:  monoprice.com\n"},{"name":"stdout","text":"gizli kelime ile kelimen arasÄ±ndaki benzerlik skoru: 1.0\nTebrikler! DoÄŸru tahmin!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"bundan sonraki cell mesafeyi Ã¶klidiyen hesaplÄ±yor. Ã–klidyen Mesafe ile VektÃ¶rel YakÄ±nlÄ±k Hesaplama\nÃ–klidyen mesafe, iki vektÃ¶r arasÄ±ndaki dÃ¼z Ã§izgi mesafesini Ã¶lÃ§er. Matematiksel olarak, iki vektÃ¶r \nğ‘£\n1\nv \n1\nâ€‹\n  ve \nğ‘£\n2\nv \n2\nâ€‹\n  arasÄ±ndaki Ã–klidyen mesafe ÅŸu ÅŸekilde hesaplanÄ±r:\n\nEuclideanÂ Distance\n=\nâˆ‘\nğ‘–\n=\n1\nğ‘›\n(\nğ‘£\n1\n,\nğ‘–\nâˆ’\nğ‘£\n2\n,\nğ‘–\n)\n2\nEuclideanÂ Distance= \ni=1\nâˆ‘\nn\nâ€‹\n (v \n1,i\nâ€‹\n âˆ’v \n2,i\nâ€‹\n ) \n2\n \n\n\nimport gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yÃ¼kle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n\n# Metin verilerini kelime listelerine dÃ¶nÃ¼ÅŸtÃ¼r\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluÅŸtur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seÃ§\n#w1 = random.choice(model.wv.index_to_key)\nW1= \"queen\"\n\ndef euclidean_distance(vec1, vec2):\n    return np.linalg.norm(vec1 - vec2)\n\nwhile True:\n    w3 = input(\"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz): \")\n\n    if w3.lower() == \"Ã§Ä±kÄ±ÅŸ\":\n        print(\"Oyunu bÄ±raktÄ±nÄ±z.\")\n        print(f\"SeÃ§ilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"LÃ¼tfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"GirdiÄŸiniz kelime modelde bulunamadÄ±.\")\n        continue\n    \n    # w1 ve w2 iÃ§in vektÃ¶rleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # Ã–klidyen mesafeyi hesapla\n    distance = euclidean_distance(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasÄ±ndaki vektÃ¶rel uzaklÄ±k: {distance}\")    \n\n    # Mesafeye dayalÄ± bir eÅŸik deÄŸeri belirleyebiliriz\n    if distance <= 0.5:  # Ã–rneÄŸin, 0.5 veya daha kÃ¼Ã§Ã¼k bir mesafe yakÄ±n kabul edilebilir\n        print(\"Tebrikler! DoÄŸru tahmin sayÄ±lÄ±r!\")\n        break\n","metadata":{}},{"cell_type":"markdown","source":"vektÃ¶rel mesafeyi pisagor teoremi ile hesaplÄ±yor sonraki cell.\n","metadata":{}},{"cell_type":"code","source":"import gensim\nimport pandas as pd\nimport random\nimport numpy as np\n\n# JSON veri setini yÃ¼kle\ndf = pd.read_json(\"/kaggle/input/cell-phones-andaccessories-5/Cell_Phones_and_Accessories_5.json\", lines=True)\n\n# Metin verilerini kelime listelerine dÃ¶nÃ¼ÅŸtÃ¼r\nreview_text = df['reviewText'].apply(lambda x: x.split()).tolist()\n\n# Word2Vec modelini oluÅŸtur\nmodel = gensim.models.Word2Vec(\n    window=10,\n    min_count=2,\n    workers=4,\n)\nmodel.build_vocab(review_text, progress_per=1000)\nmodel.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\nmodel.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n\n# Modeldeki kelimelerden rastgele birini seÃ§\nw1 = random.choice(model.wv.index_to_key)\n#w1=\"queen\"\n\ndef pythagorean_distance(vec1, vec2):\n    # BileÅŸen farklarÄ±nÄ±n karelerini topla ve karekÃ¶kÃ¼nÃ¼ al\n    return np.sqrt(np.sum((vec1 - vec2) ** 2))\n\nwhile True:\n    w3 = input(\"rastgele bir ÅŸeyler yaz devam etmek iÃ§in (Ã§Ä±kmak iÃ§in 'Ã§Ä±kÄ±ÅŸ' yaz): \")\n\n    if w3.lower() == \"Ã§Ä±kÄ±ÅŸ\":\n        print(\"Oyunu bÄ±raktÄ±nÄ±z.\")\n        print(f\"SeÃ§ilen kelime: {w1}\")\n        break\n    \n    w2 = input(\"LÃ¼tfen bir kelime giriniz: \")\n        \n    if w2 not in model.wv:\n        print(\"GirdiÄŸiniz kelime modelde bulunamadÄ±.\")\n        continue\n    \n    # w1 ve w2 iÃ§in vektÃ¶rleri al\n    vec1 = model.wv[w1]\n    vec2 = model.wv[w2]\n    \n    # Pisagor Teoremi ile mesafeyi hesapla\n    distance = pythagorean_distance(vec1, vec2)\n    print(f\"gizli kelime ile kelimen arasÄ±ndaki vektÃ¶rel uzaklÄ±k: {distance}\")    \n\n    # Mesafeye dayalÄ± bir eÅŸik deÄŸeri belirleyebiliriz\n    if distance <= 0.5:  # Ã–rneÄŸin, 0.5 veya daha kÃ¼Ã§Ã¼k bir mesafe yakÄ±n kabul edilebilir\n        print(\"Tebrikler! DoÄŸru tahmin sayÄ±lÄ±r!\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:43:16.114887Z","iopub.execute_input":"2024-09-30T09:43:16.115400Z"},"trusted":true},"execution_count":null,"outputs":[]}]}